\chapter{Arquitectura del Chatbot}
\label{cap:arquitectura}

Los sistemas de análisis automático de texto tienen como objetivo entender la información no estructurada hablada por los humanos y convertirla en información estructurada como podría ser un resumen del contenido o la clasificación de un documento por temática. En este caso, el objetivo del chatbot es conseguir esta información estructurada a partir de la mayor cantidad de recuerdos posibles para ayudar a los terapeutas a construir la historia de vida de un paciente que es mucho más complicada de tratar en bruto. El análisis se va a realizar en varios sentidos, por un lado, se clasificarán los recuerdos en etapas de vida, para estructurar la información lo máximo posible. Por otro lado, se determinará si el texto contiene connotaciones positivas o negativas, de tal forma que en la terapia se puedan evitar los recuerdos negativos que pueden agravar la situación del paciente. Por último, se utilizará el procesamiento del lenguaje natural mediante el análisis morfológico de las palabras para comprender lo que quiere decir el paciente y poder generar la respuesta más acertada y relacionada con la temática que se está tratando. 

\section{Clasificación de los recuerdos}

La clasificación de los recuerdos en positivos y negativos y la clasificación en etapas de vida se consiguen utilizando el mismo método. Se ha utilizado el componente ``TextCategorizer'' \footnote{https://spacy.io/api/textcategorizer} de la librería spacy de python. Se trata de entrenar un modelo para saber identificar si un recuerdo es positivo o negativo o para poder clasificar el recuerdo en diferentes etapas de la vida. Este método de clasificación se ha probado primero para el análisis de sentimiento de los recuerdos y es por eso que se empezará a explicar cómo funciona el categorizador para el \textit{sentiment analysis}. Más adelante en esta sección se explicará cómo se adaptó para la clasificación en etapas. 

Para conseguir que funcione el categorizador de textos se ha utilizado como guía el código del artículo \textit{How to Train Text Classification Model in spaCy} \footnote{https://www.machinelearningplus.com/nlp/custom-text-classification-spacy/} para probar cómo se podría entrenar el modelo para que supiese diferenciar los recuerdos negativos de los positivos y así tener la primera clasificación que pidieron los terapeutas especializados del proyecto CANTOR. Antes de probar con recuerdos se probó con un dataset muy grande de reseñas de moda que se ponía como ejemplo en el artículo del que hablábamos anteriormente. Después, se ha probado usando una batería menor de recuerdos positivos encontrados entre los archivos del TFG de Laura Castillo \citep{reminiscencia}. También había que incluir recuerdos negativos y, como no se ha encontrado ningún dataset ni textos relacionados, se han usado frases negativas inventadas pensadas para entrenar el modelo de la mejor manera posible.

El análisis de sentimiento de los recuerdos funciona siguiendo una serie de pasos. En primer lugar, se añade el componente TextCategorizer (textcat) a un modelo en blanco del idioma español. Un modelo en blanco es un modelo que no tiene ningún componente de spaCy definido (como serían NER que explicaré más adelante), es decir, el texto que se almacena en los documentos de spaCy no es analizado por ninguna cadena de procesos porque la tubería de componentes está vacía. Si hubiésemos cogido un modelo pre-entrenado como ``es\_core\_news\_sm'', el clasificador de textos se sumaría al trabajo previo de los procesos que analizan el texto como serían ['tok2vec', 'morphologizer', 'parser', 'attribute\_ruler', 'lemmatizer', 'ner']. Por ejemplo, el componente NER, más reconocido como \textit{Named Entity Recognizer}, reconoce entidades dentro del texto como nombres de personas, fechas o lugares. Al usar el modelo en blanco empezamos con el español de cero, sin analizar. Tras añadir el componente textcat, al crear un documento de spaCy, automáticamente, pasará por el proceso de clasificación que le indiquemos. Para que textcat funcione como categorizador de recuerdos, se le añade a nuestro nuevo componente dos etiquetas, NEGATIVO y POSITIVO, que definirán cuánto de negativo es un recuerdo y cuánto de positivo. Para seguir configurándolo, el prototipo coge el texto que usaremos para entrenar nuestro modelo y lo prepara adecuándolo al formato que entiende el clasificador, siendo éste una lista de tuplas (texto, etiqueta). Además, cogerá un porcentaje de esta batería de recuerdos (\% que previamente hemos definido) y lo reservará para la evaluación de las predicciones, es decir, para analizar cómo de bien predice nuestro modelo tras entrenarlo. 

Ya tenemos casi todo preparado para comenzar a entrenar el modelo, se dividen los casos de entrenamiento en lotes que se analizarán y evaluarán un número definido de iteraciones para asegurar que el entrenamiento es lo más preciso posible sin pasarnos de vueltas para que sea óptimo. Se trata de un proceso iterativo en el que las predicciones del modelo se comparan con las etiquetas de referencia para estimar el gradiente de la pérdida. El modelo se entrena utilizando una función que lo analiza y actualiza en cada iteración, la función update(). También se comprueban las predicciones del modelo en cada vuelta, se comparan con las etiquetas de referencia para estimar la desviación de la pérdida.

Una vez afinado el modelo mediante el entreno previo, ya podemos ponerlo a prueba. El prototipo sacará la probabilidad de que un texto procesado por spacy sea un recuerdo positivo y la probabilidad de que sea uno negativo. En lo relativo al chatbot, se ha añadido se ha añadido el archivo ``analyze\_answer'' que alberga esta funcionalidad de análisis de sentimientos que, como se ha explicado, entrena primero al modelo con textos positivos y negativos y luego evalúa el texto que le llega del usuario e identifica si es negativo o positivo. Esto se utilizará como una de las categorías que se le asignan a cada respuesta recibida y que se mete en una base de datos junto a la respuesta que haya dado el usuario al chatbot. Este análisis de sentimiento también servirá para identificar temáticas dolorosas para el interrogado que no deberían ser usadas en las terapias.

Más adelante en el proyecto, se observó que, al analizar el sentimiento de la frase, había recuerdos o simplemente, datos que no encajaban en ninguna de las dos categorías de positivo y negativo. Las emociones neutras son aquellas que no son desagradables ni agradables, es decir, ni negativas ni positivas. Es por esto que se probó a añadir una nueva categoría para los datos neutro como por ejemplo, indicar tu edad, explicar dónde vivías en cierto momento de tu vida, etc. No suponía un gran esfuerzo porque el programa estaba pensado para poder añadir todas las categorías que se considerasen. Sin embargo, a niveles prácticos, se pudo comprobar que no funcionaba igual de bien que la clasificación binaria. El nivel de entrenamiento que necesitaría el modelo para poder distinguir también las frases neutras es mucho mayor, es decir, se necesitarían muchos más casos, ejemplos, para que el modelo aprendiese de ellos. En nuestro caso, solo se añadieron alrededor de 40 recuerdos neutros, de nuevo inventados, por la falta de recursos encontrados en Internet que no proporcionaba ningún dataset parecido al que se buscaba. En la siguiente sección de pruebas se podrá comprobar la diferencia entre meter la categoría neutra y no meterla. 

\subsection{Pruebas del análisis de sentimiento}

Para comprobar la precisión y el correcto funcionamiento del módulo de análisis de sentimiento, se hicieron bastantes pruebas que corroboraron que la clasificación en recuerdos negativos y positivos funcionaba bastante bien pero que podría mejorarse metiendo muchos más casos de entrenamiento para afinar el modelo. A continuación se muestran algunos ejemplos de frases que se han analizado con el categorizador de textos y las conclusiones que se han sacado. Entre llaves se muestra la probabilidad sobre 1 de que la frase sea positiva y la probabilidad sobre 1 de que sea negativa. Entre corchetes se muestra la categoría a la que pertenece la frase por tener la mayor probabilidad las dos:

\begin{itemize}
	\item ``Mi abuela se murió en 1998''
	\begin{verbatim}
		{'POSITIVO': 0.09926079958677292, 'NEGATIVO': 0.9007392525672913}
		['negativo']
	\end{verbatim}
	\item ``Mi mejor recuerdo es el del nacimiento de mi hijo''
	\begin{verbatim}
		{'POSITIVO': 0.992607593536377, 'NEGATIVO': 0.007392475381493568}
		['positivo']
	\end{verbatim}
	\item ``Tengo 23 años''
	\begin{verbatim}
		{'POSITIVO': 0.9999983310699463, 'NEGATIVO': 1.6568293403906864e-06}
		['positivo']
	\end{verbatim}
	\item ``Me dolió muchísimo cuando me rompí una pierna''
	\begin{verbatim}
		{'POSITIVO': 2.0322097043390386e-05, 'NEGATIVO': 0.9999797344207764}
		['negativo']
	\end{verbatim}
	\item ``Mi hermano y yo nos pasabamos las tardes haciendo puzzles''
	\begin{verbatim}
			{'POSITIVO': 0.9681606888771057, 'NEGATIVO': 0.031839337199926376}
		['positivo']
	\end{verbatim}
	\item ``Durante la infancia estuvimos viviendo en Moratalaz''
	\begin{verbatim}
		{'POSITIVO': 0.9882893562316895, 'NEGATIVO': 0.011710633523762226}
		['positivo']
	\end{verbatim}
	\item ``Mi pareja sufrió depresión después del parto''
	\begin{verbatim}
		{'POSITIVO': 0.07562904059886932, 'NEGATIVO': 0.9243709444999695}
		['negativo']
	\end{verbatim}

\end{itemize}

Por otro lado, también se probó cómo funcionaba el programa añadiendo la clasificación de neutro. Podemos comparar así ambas formas de clasificación y comprobar que, efectivamente, funciona mejor el binario. De nuevo, entre llaves se muestra la probabilidad sobre 1 de que la frase sea positiva, la probabilidad sobre 1 de que sea negativa y la probabilidad sobre 1 de que sea neutra. Entre corchetes se muestra la categoría a la que pertenece la frase por tener la mayor probabilidad de todas:

\begin{itemize}
	\item ``Mi abuela se murió en 1998''
	\begin{verbatim}
		{'POSITIVO': 0.000133998051751405, 'NEGATIVO': 0.00039583168108947575,
			'NEUTRO': 0.9994701743125916}
		['neutro']
	\end{verbatim}
	\item ``Mi mejor recuerdo es el del nacimiento de mi hijo''
	\begin{verbatim}
		{'POSITIVO': 0.0003367967437952757, 'NEGATIVO': 0.9894788861274719, 
			'NEUTRO': 0.010184396989643574}
		['negativo']
	\end{verbatim}
	\item ``Tengo 23 años''
	\begin{verbatim}
		{'POSITIVO': 0.016445694491267204, 'NEGATIVO': 0.0031412760727107525, 
			'NEUTRO': 0.980413019657135}
		['neutro']
	\end{verbatim}
	\item ``Me dolió muchísimo cuando me rompí una pierna''
	\begin{verbatim}
		{'POSITIVO': 0.0006958534941077232, 'NEGATIVO': 0.9989858269691467, 
			'NEUTRO': 0.0003183614171575755}
		['negativo']
	\end{verbatim}
	\item ``Mi hermano y yo nos pasabamos las tardes haciendo puzzles''
	\begin{verbatim}
		{'POSITIVO': 2.354631942580454e-05, 'NEGATIVO': 0.9972598552703857, 
			'NEUTRO': 0.0027166458312422037}
		['negativo']
	\end{verbatim}
	\item ``Durante la infancia estuvimos viviendo en Moratalaz''
	\begin{verbatim}
		{'POSITIVO': 0.051713500171899796, 'NEGATIVO': 0.9064642786979675, 
			'NEUTRO': 0.041822321712970734}
		['negativo']
	\end{verbatim}
	\item ``Mi pareja sufrió depresión después del parto''
	\begin{verbatim}
		{'POSITIVO': 2.2260337573243305e-05, 'NEGATIVO': 0.9954761862754822, 
			'NEUTRO': 0.004501543939113617}
		['negativo']
	\end{verbatim}
	
\end{itemize}


\subsection{Clasificación en etapas de vida}

Otra de las categorías que se añadirá junto a la respuesta en la base de datos de recuerdos será la de la etapa de vida a la que corresponde el recuerdo. Primero había que definir esas etapas y para ello, en un principio se utilizó de forma orientativa la clasificación que hace el Ministerio de Salud de Colombia \ref{https://www.minsalud.gov.co/proteccionsocial/Paginas/cicloVida.aspx} porque no se encontraron clasificaciones tan claras para España y parecía una forma sensata de clasificación. Como en el caso del análisis de sentimiento, se han probado varias combinaciones de Le he hecho algunas modificaciones para adecuarme más a lo que quería sacar en claro de la información que se me presentaba. Las etapas serían las siguientes:

Otra de las categorías que se añadirá junto a la respuesta en la base de datos de recuerdos será la de la etapa de vida a la que corresponde el recuerdo. En un principio, había que definir las etapas y se decidió usar de forma orientativa la clasificación que hace el Ministerio de Salud de Colombia \ref{https://www.minsalud.gov.co/proteccionsocial/Paginas/cicloVida.aspx} porque no se encontraron fuentes fiables españolas que diesen una clasificación tan clara y sensata. Aún así se le hicieron algunas adecuaciones para que se ajustase más a lo que se buscaba y lo que se quería sacara en claro. Además, como en el caso del análisis de sentimiento con el neutro, se decidió desde un principio añadir la clasificación ``Indeterminado'' para aquellos recuerdos que no encajasen en ninguna etapa porque fuesen datos generales. Aquí se veía más claro que había información de los usuarios que era muy general y que por defecto no podía meterse en ninguna otra etapa. Sin embargo, pasaba lo mismo que con el neutro, la clasificación era mucho menos acertada. Más adelante se explicará con más detalle. A continuación se muestra la clasificación inicial que se eligió:

\begin{itemize}
	\item Infancia de 0 a 11 años
	\item Adolescencia de 12 a 17 años
	\item Juventud de 18 a 26 años
	\item Etapa adulta de 27 a 59 años
	\item Vejez de 60 años o más
	\item Indeterminado para aquellos textos en los que no se pueda distinguir la etapa
\end{itemize}

Una vez elegidos los periodos de tiempo en los que se divide la vida de las personas, el objetivo era clasificar recuerdos, dados en forma de respuesta a una pregunta, según la etapa de la vida a la que pertenecía el recuerdo de la persona interrogada. Para ello, también se ha utilizado la misma tecnología que para el análisis de sentimientos. Además de entrenarse en recuerdos positivos y negativos, ahora el modelo se entrena para distinguir etapas vitales en las que ocurren los recuerdos para así, de cara a la elaboración de un libro de vida, toda la información esté bien estructurada en periodos de tiempo. 

Como se explicaba al principio, la clasificación que se eligió inicialmente no resultó dar buenos resultados. El nivel de entrenamiento que necesitaría el modelo para poder distinguir también los recuerdos que no encajan en ninguna de las etapas anteriores es mucho mayor. Además, resultaba muy ambigua la etapa indeterminada porque los recuerdos que se meten en esa clasificación no tienen relación entre ellos para el modelo, no puede aprender de similitudes porque cada recuerdo es muy distinto y muy general. Algo parecido pasaba con la etapa de la adolescencia, no se aprecia bien en los ejemplos la diferencia entre la etapa de la adolescencia y la de la juventud porque no existen ejemplos que hagan una buena distinción entre la una y la otra ya que son muy parecidos los sucesos que podrían ocurrir en una y en la otra. Es por eso que se ha decidido quitar ambas etapas y ponérselo mucho más fácil al modelo para que pueda reconocer bien los recuerdos y no confundirse tan fácilmente. En la sección de pruebas se ve claramente la diferencia entre ambos casos. Finalmente, se ha elegido una  clasificación muy clara según los hechos que suelen pasar en la vida de las personas en las distintas etapas y para los que cada etapa tiene ejemplos precisos y nada ambiguos. Se hace la siguiente división:

\begin{itemize}
	\item Infancia de 0 a 12 años
	\item Juventud de 13 a 26 años
	\item Etapa adulta de 27 a 59 años
	\item Vejez de 60 años o más
\end{itemize}


\subsubsection{Pruebas}

Se comprueba la precisión y el correcto funcionamiento del módulo de clasificación en etapas de vida, se hicieron bastantes pruebas que indicaron que la clasificación funcionaba bastante bien pero que podría mejorarse metiendo muchos más casos de entrenamiento para afinar el modelo. La clasificación definitiva como se explicaba anteriormente era la que distinguía las etapas de infancia, juventud, etapa adulta y vejez. A continuación se muestran algunos ejemplos de frases que se han analizado con el categorizador de textos y las conclusiones que se han sacado. Entre llaves se muestra la probabilidad sobre 1 de que la frase se corresponda con la fase de la infancia, la probabilidad sobre 1 de que se corresponda con la fase de la juventud, la probabilidad sobre 1 de que se corresponda con la fase de la etapa adulta y la probabilidad sobre 1 de que se corresponda con la fase de la vejez. Entre corchetes se muestra la categoría a la que pertenece la frase por tener la mayor probabilidad de todas:

\begin{itemize}
	\item ``Mi mejor recuerdo es el del nacimiento de mi hijo''
	\begin{verbatim}
		{'INFANCIA': 0.003423456335440278, 'JUVENTUD': 0.004028527531772852, 
			'ETAPA ADULTA': 0.979805052280426, 'VEJEZ': 0.012742995284497738}
		['etapa adulta']
	\end{verbatim}
	\item ``Me dolió muchísimo cuando me rompí una pierna a los 22 años''
	\begin{verbatim}
		{'INFANCIA': 0.07795873284339905, 'JUVENTUD': 0.7799875736236572, 
			'ETAPA ADULTA': 0.07531660795211792, 'VEJEZ': 0.0667370930314064}
		['juventud']
	\end{verbatim}
	\item ``Mi hermano y yo nos pasábamos las tardes haciendo puzles''
	\begin{verbatim}
		{'INFANCIA': 0.9991468191146851, 'JUVENTUD': 0.00011972746870014817, 
			'ETAPA ADULTA': 0.00013617362128570676, 'VEJEZ': 0.0005973773077130318}
		['infancia']
	\end{verbatim}
	\item ``Durante la infancia estuvimos viviendo en Moratalaz''
	\begin{verbatim}
		{'INFANCIA': 0.9864945411682129, 'JUVENTUD': 0.0020768800750374794, 
			'ETAPA ADULTA': 0.005027524195611477, 'VEJEZ': 0.0064010825008153915}
		['infancia']
	\end{verbatim}
	\item ``Mi pareja sufrió depresión después del parto''
	\begin{verbatim}
		{'INFANCIA': 0.10760761052370071, 'JUVENTUD': 0.003418843261897564, 
			'ETAPA ADULTA': 0.8073434829711914, 'VEJEZ': 0.08163014054298401}
		['etapa adulta']
	\end{verbatim}
	\item ``Mi tía siempre se dedicó a la pintura''
	\begin{verbatim}
		{'INFANCIA': 0.15463659167289734, 'JUVENTUD': 0.2145996242761612, 
			'ETAPA ADULTA': 0.5623230338096619, 'VEJEZ': 0.0684407576918602}
		['etapa adulta']
	\end{verbatim}
	\item ``Cuando estudiaba en el instituto teníamos tres gatos''
	\begin{verbatim}
		{'INFANCIA': 0.07519558817148209, 'JUVENTUD': 0.6477565169334412, 
			'ETAPA ADULTA': 0.23660382628440857, 'VEJEZ': 0.040444087237119675}
		['juventud']
	\end{verbatim}
	
\end{itemize}

También se probó cómo funcionaba el modelo en un principio cuando en la clasificación estaban las etapas de adolescencia y la indeterminada. Se puede comparar así ambas formas de clasificación y comprobar que, efectivamente, funciona mejor la que tiene menos categorías y mucho más diferenciadas. De nuevo, entre llaves se muestra la probabilidad sobre 1 de cada una de las fases y, entre corchetes se muestra la categoría a la que pertenece la frase por tener la mayor probabilidad de todas:

\begin{itemize}
	\item ``Mi mejor recuerdo es el del nacimiento de mi hijo''
	\begin{verbatim}
		{'INFANCIA': 0.11781484633684158, 'ADOLESCENCIA': 0.29379358887672424, 
			'JUVENTUD': 0.22842659056186676, 'ETAPA ADULTA': 0.20501598715782166, 
			'VEJEZ': 0.10608396679162979, 'INDETERMINADO': 0.04886503145098686}
		['adolescencia']
	\end{verbatim}
	\item ``Me dolió muchísimo cuando me rompí una pierna a los 22 años''
	\begin{verbatim}
		{'INFANCIA': 0.0013075786409899592, 'ADOLESCENCIA': 0.0039981659501791, 
			'JUVENTUD': 0.9936805963516235, 'ETAPA ADULTA': 0.0006605012458749115, 
			'VEJEZ': 0.00015935904229991138, 'INDETERMINADO': 0.00019375460396986455}
		['juventud']
	\end{verbatim}
	\item ``Mi hermano y yo nos pasábamos las tardes haciendo puzles''
	\begin{verbatim}
		{'INFANCIA': 0.9913138747215271, 'ADOLESCENCIA': 0.0026805144734680653, 
			'JUVENTUD': 0.0005102856084704399, 'ETAPA ADULTA': 0.0003391568607185036, 
			'VEJEZ': 0.00324622611515224, 'INDETERMINADO': 0.0019098836928606033}
		['infancia']
	\end{verbatim}
	\item ``Durante la infancia estuvimos viviendo en Moratalaz''
	\begin{verbatim}
		{'INFANCIA': 0.9902841448783875, 'ADOLESCENCIA': 0.0011972723295912147, 
			'JUVENTUD': 0.007258791010826826, 'ETAPA ADULTA': 0.00017597108671907336, 
			'VEJEZ': 0.0006049419171176851, 'INDETERMINADO': 0.00047876848839223385}
		['infancia']
	\end{verbatim}
	\item ``Mi pareja sufrió depresión después del parto''
	\begin{verbatim}
		{'INFANCIA': 0.9323758482933044, 'ADOLESCENCIA': 0.011906568892300129, 
			'JUVENTUD': 0.018807733431458473, 'ETAPA ADULTA': 0.008572818711400032, 
			'VEJEZ': 0.025070885196328163, 'INDETERMINADO': 0.0032660840079188347}
		['infancia']
	\end{verbatim}
	\item ``Mi tía siempre se dedicó a la pintura''
	\begin{verbatim}
		{'INFANCIA': 7.487166294595227e-05, 'ADOLESCENCIA': 0.00675414502620697, 
			'JUVENTUD': 0.0021927112247794867, 'ETAPA ADULTA': 0.9876710176467896, 
			'VEJEZ': 0.0032006383407860994, 'INDETERMINADO': 0.00010662782733561471}
		['etapa adulta']
	\end{verbatim}
	\item ``Cuando estudiaba en el instituto teníamos tres gatos''
	\begin{verbatim}
		{'INFANCIA': 0.9774642586708069, 'ADOLESCENCIA': 0.005647959187626839, 
			'JUVENTUD': 0.012261644005775452, 'ETAPA ADULTA': 0.0004069636052008718, 
			'VEJEZ': 0.0033992205280810595, 'INDETERMINADO': 0.0008198729483410716}
		['infancia']
	\end{verbatim}
	
\end{itemize}



\section{Procesamiento del texto para encadenar preguntas y respuestas}
 
Esta sección consiste en conseguir que las preguntas que se hagan al interrogado tengan sentido con el resto de la conversación previa. Conseguir que sean lo más inteligentes y adecuadas posible. 

Lo primero que se ha hecho para encontrar la siguiente pregunta a hacer es coger la lista de todas las posibles preguntas y eliminar aquellas que ya han sido contestadas anteriormente para no repetirlas. 

Lo siguiente que se hará es pasar tanto la respuesta más reciente que ha dado el interrogado como todas las posibles preguntas por un proceso de síntesis. Para ello vamos a utilizar el analizador de texto Spacy utilizando el código del TFG de Laura Castilla Castellano (Generación de historias a partir de una base de conocimiento), en concreto el código que aparece en el archivo ``analysis.py'' de su código, que contiene funciones para el procesamiento y síntesis de los textos. Los pasos que Laura sigue para el análisis del texto aparecen en el apartado 5.1 (Analizar textos para obtener sugerencias) de su memoria, páginas 30 y 31. Las funciones que se han reutilizado en este trabajo, con algunas modificaciones, son las siguientes:

\begin{itemize}
	\item Read: Coge el texto a analizar y elimina signos de puntuación
	\item Synthesis: Elimina las palabras vacías como las preposiciones del texto
	\item Lemmatize: Transforma cada palabra del texto sus lemas correspondientes
	\item Categorize: Separa las palabras en sustantivos, verbos y adjetivos. Además, coge los 30 más comunes de cada tipo
	\item Get\_most\_common\_words: Coge las palabras más comunes de todos los tipos del texto
\end{itemize}

Estas funciones se han utilizado para conseguir una representación del texto más precisa y reducida. Solo los lemas de las palabras importantes del texto serán usados para este módulo de encadenamiento de preguntas y respuestas.

Por último, dada la respuesta y todas las posibles preguntas ya reducidas a sus lemas, para encontrar la pregunta más adecuada, se compara una a una los lemas de las posibles preguntas con los lemas de la respuesta. Dentro de la lista de posibles preguntas, la que más lemas comunes tenga con la respuesta, gana como siguiente pregunta a formular.

\subsection{Pruebas}
Veamos algunos ejemplos de cómo funciona el primer acercamiento a un chatbot inteligente que pregunta con algo de sentido. A continuación se muestra la primera pregunta y la respuesta del interrogado:

\begin{itemize}
	\item[] IA: ¿Quiénes son las personas más importantes de tu vida?
	\item[] Tú: Mi familia y concretamente mis padres y mi hermano
\end{itemize}

En el siguiente texto de salida por consola se muestra el análisis que hace el módulo de cálculo de la mejor siguiente pregunta:

\begin{verbatim}
	
	Maxima coincidencia de lemas hasta ahora: 0
	Pregunta elegida hasta ahora: ¿Cuál es tu sexo?
	
	Posible pregunta: ¿Hay algún momento que te gustaría volver a vivir?
	Lemas de la posible pregunta: {'volver', 'vivir', 'momento', 'gustar'}
	Lemas de la respuesta anterior: {'familia', 'padre', 'hermano'}
	Lemas que coinciden: 0
	-----------------------------------------------
	Maxima coincidencia de lemas hasta ahora: 0
	Pregunta elegida hasta ahora: ¿Cuál es tu sexo?
	
	Posible pregunta: ¿Dónde viviste cuando eras pequeño?
	Lemas de la posible pregunta: {'pequeño', 'vivistar'}
	Lemas de la respuesta anterior: {'familia', 'padre', 'hermano'}
	Lemas que coinciden: 0
	-----------------------------------------------
	Maxima coincidencia de lemas hasta ahora: 0
	Pregunta elegida hasta ahora: ¿Cuál es tu sexo?
	
	Posible pregunta: ¿Has vivido en algún lugar diferente cuando eras pequeño?
	Lemas de la posible pregunta: {'lugar', 'pequeño', 'vivir'}
	Lemas de la respuesta anterior: {'familia', 'padre', 'hermano'}
	Lemas que coinciden: 0
	-----------------------------------------------
	Maxima coincidencia de lemas hasta ahora: 0
	Pregunta elegida hasta ahora: ¿Cuál es tu sexo?
	
	Posible pregunta: ¿Cómo se llaman tus padres?
	Lemas de la posible pregunta: {'padre', 'llamar'}
	Lemas de la respuesta anterior: {'familia', 'padre', 'hermano'}
	Lemas que coinciden: 1
	-----------------------------------------------
	Maxima coincidencia de lemas hasta ahora: 1
	Pregunta elegida hasta ahora: ¿Cómo se llaman tus padres?
	
	Posible pregunta: ¿Si tienes hermanos, cómo se llaman?
	Lemas de la posible pregunta: {'llamar', 'tener', 'hermano'}
	Lemas de la respuesta anterior: {'familia', 'padre', 'hermano'}
	Lemas que coinciden: 1
	-----------------------------------------------
	Maxima coincidencia de lemas hasta ahora: 1
	Pregunta elegida hasta ahora: ¿Cómo se llaman tus padres?
	
	Posible pregunta: ¿Cómo era la casa dónde viviste de pequeño?
	Lemas de la posible pregunta: {'pequeño', 'casa', 'vivistar'}
	Lemas de la respuesta anterior: {'familia', 'padre', 'hermano'}
	Lemas que coinciden: 0
\end{verbatim}


En el texto podemos observar el análisis de varias posibles preguntas. La separación entre preguntas se marca con una fila de guiones. En cada apartado nos encontramos con el número de lemas que han coincidido en preguntas anteriores, después con la pregunta que hasta el momento va ganando como candidata a ser preguntada, con la posible pregunta, con los lemas más relevantes de la posible pregunta entre llaves y con los lemas de la respuesta entre llaves. Las tres primeras preguntas no serán elegidas como candidatas a ser preguntadas porque no coincide ningún lema de la respuesta con los lemas de la posible pregunta, es decir, no mejora el número de coincidencias. Cuando llega a la cuarta pregunta, ``¿Cómo se llaman tus padres?'' va a encontrar una coincidencia de tal forma:

\begin{itemize}
	\item[] Lemas de la respuesta: \hspace{2cm} \{hermano, familia, padre\} 
	\item[] Lemas de la posible pregunta: \hspace{0.8cm} \{llamar, padre\}
\end{itemize}

Como podemos observar el lema ``padre'' coincide en ambas, es decir, en esta posible pregunta encontramos una coincidencia. Como el número de coincidencias es mejor que 0, la pregunta candidata ``¿Cuál ha sido el momento más feliz de tu vida?'' se sustituye por la pregunta ``¿Cómo se llaman tus padres?''. Es por esto que cuando analizamos el resto de posibles preguntas, no encontramos ninguna que sea mejor porque no superan el número de coincidencias en lemas. En conclusión, esta será la siguiente pregunta que se le plantee al usuario, la cual tiene relación con la que se había hecho anteriormente. 

\section{Base de datos MongoDB}